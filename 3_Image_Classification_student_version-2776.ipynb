{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "q4sO-peK5nPe"
   },
   "source": [
    "# Introduction to Image Classification\n",
    "Â© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to Students\n",
    "- **Do not add or remove cells in this notebook. Do not edit or remove the `### START FUNCTION` or `### END FUNCTION` comments. Do not add any code outside of the functions you are required to edit. Doing any of this will lead to a mark of 0%!**\n",
    "- Answer the questions according to the specifications provided.\n",
    "- Use the given cell in each question to to see if your function matches the expected outputs.\n",
    "- Do not hard-code answers to the questions.\n",
    "- The use of stackoverflow, google, and other online tools are permitted. However, copying fellow student's code is not permissible and is considered a breach of the Honour code below. Doing this will result in a mark of 0%.\n",
    "- Good luck, and may the force be with you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honour Code\n",
    "I **SITHOMILE, MBUYAZI**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).  \n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rio6wWWK5nPg"
   },
   "source": [
    "## Overview\n",
    "\n",
    "The versatile Machine Learning techniques you have been learning will enable you to process complex and different data at a faster pace. Luckily for us, this is exactly what we're being tested on. So far you have performed classification on both tabular [the iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) and textual data [the mbti dataset](https://www.kaggle.com/datasnaek/mbti-type). In this test you will apply the machine learning techniques you have learned for image classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jrCXrw5X5nPk"
   },
   "source": [
    "## Imports\n",
    "\n",
    "Let's go ahead and load our libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQbyemE45nPp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip # This is used in extracting the images\n",
    "\n",
    "import matplotlib.pyplot as plt # In order to plot the images to see what we are dealing with\n",
    "from sklearn.ensemble import RandomForestClassifier # You'll be using Random Forest to classify the images\n",
    "from sklearn.metrics import accuracy_score # Sklearn's way of measuring accuracy\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XG1aYu7_5nP1"
   },
   "source": [
    "## The Dataset\n",
    "The dataset we will be using is called MNIST. This is a large collection of handdrawn digits 0-9 and is a good dataset to learn image classification on as it requires little to no preprocessing.\n",
    "\n",
    "The dataset can be downloaded from [The MNIST Database](http://yann.lecun.com/exdb/mnist/). Download all four files. These files are the images and their respective labels and the dataset has already been split into a train and a test set.\n",
    "\n",
    "Once you've downloaded the data, make sure that the data is in the same folder as this Jupyter Notebook. If you've managed to do all that, we can now begin! \n",
    "\n",
    "By default, the MNIST files are compressed in the gzip format. The following two functions will extract the data for you. ** **Don't change this code.** **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-62g3Rdn5nP9"
   },
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images, IMAGE_WIDTH):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\"\"\"\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_WIDTH * IMAGE_WIDTH * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, IMAGE_WIDTH*IMAGE_WIDTH)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aY2_-9ai5nQF"
   },
   "source": [
    "## Question 1 - Extracting the data\n",
    "\n",
    "The MNIST dataset consists for 60 000 training images and 10 000 testing images. This is a lot of data! Let's not extract all of that right now. Create a function `get_data` that uses the above functions to extract a certain number of images and their labels from the gzip files.\n",
    "\n",
    "The function will take as input two integer values and return four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the extracted images / labels of the training set, and `(X-test, y_test)` are the extracted images / labels of the testing set.\n",
    "\n",
    "Image pixel values range from 0-255. Normalise the image pixels so that they are in the range 0-1.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two integers as input, one representing the number of training images, and the other the number of testing images.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
    "\n",
    "_**Note**_ that the size of the MNIST images are 28x28\n",
    "\n",
    "Usually when setting up your dataset, it is a good idea to randomly shuffle your data in case your data is ordered. Think of this as shuffling a pack of cards. Here, however, we aren't going to shuffle the data so that all our answers are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BpvzeRX5nQJ"
   },
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def get_data(num_train_images,num_test_images):\n",
    "    X_train = extract_data('train-images-idx3-ubyte.gz', num_train_images, 28)/255\n",
    "    y_train = extract_labels('train-labels-idx1-ubyte.gz', num_train_images)\n",
    "    X_test  = extract_data( 't10k-images-idx3-ubyte.gz', num_test_images, 28)/255\n",
    "    y_test  = extract_labels('t10k-labels-idx1-ubyte.gz', num_test_images)\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2rS86Dw5nQT",
    "outputId": "6e82889f-284b-4213-80a7-1552032c7277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "(1000,)\n",
      "(5000, 784)\n",
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_data(5000,1000)\n",
    "## Print off the shape of these arrays to see what we are dealing with\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3j32G5d5nQd"
   },
   "source": [
    "** Expected Output **\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test) = get_data(5000,1000)\n",
    "## Print off the shape of these arrays to see what we are dealing with\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "(5000,)\n",
    "(1000,)\n",
    "(5000, 784)\n",
    "(1000, 784)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10980392"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1,349]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_test[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPSr43Tl5nQf"
   },
   "source": [
    "## Plotting the Data\n",
    "Let's see what this data looks like! Right now the images are \"flattened\" into a 1-D array of length 784. In order to plot the image we first need to reshape it to the correct size of 28x28. We'll print out the respective label to make sure we are plotting the right number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLi4Odvo5nQj",
    "outputId": "7d835666-70e3-42d1-d2e5-74f531f704ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 3 ## Change me to view different images\n",
    "\n",
    "print(\"Label: \", y_train[image_index])\n",
    "reshaped_image = X_train[image_index].reshape((28, 28))\n",
    "\n",
    "plt.imshow(reshaped_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9X1bnDB5nQv"
   },
   "source": [
    "## Question 2 - Training the Model\n",
    "Now that we have formatted our data, we can fit a model using sklearn's `RandomForestClassifier` class with 20 estimators and its random_state is set to 42. We'll write a function that will take as input the image and label variables that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `RandomForestClassifier` model which has a random state of 42 and number of estimators 20.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nqo-XA1f5nQz"
   },
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def train_model(X_train, y_train):\n",
    "    classifier = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vl5cToJm5nQ5",
    "outputId": "3034441e-47f9-46d0-f0bf-c0170aea93f5"
   },
   "outputs": [],
   "source": [
    "clf = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHN3AL3W5nRG"
   },
   "source": [
    "## Question 3 - Testing the model\n",
    "Now that you have trained your model, lets see how well it does on the test set. Write a function which returns the accuracy of your trained model when tested with the test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a `float` of the accuracy of the model. This number should be between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMCnj6x85nRO"
   },
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def calculate_accuracy(clf, X_test, y_test):\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-pqCRlXD5nRS",
    "outputId": "5f40a78b-8670-4a47-aa55-d4eea51b617a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891\n"
     ]
    }
   ],
   "source": [
    "print(calculate_accuracy(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YsvYXM_h5nRi"
   },
   "source": [
    "Classification reports gives us more information on where our model is going wrong - looking specifically at the performance caused by Type I & II errors. Write a function which returns the classification report of your test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a classification report\n",
    "\n",
    "_**Hint**_ You don't need to do this manually, sklearn has a classification report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qv8ndyM05nRl"
   },
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def get_class_report(clf, X_test, y_test):\n",
    "    #your code here\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    return classification_report(y_test, y_pred_test)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmtLlUT_5nRt",
    "outputId": "c4f52542-456b-4d61-c730-b1a040551469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97        85\n",
      "           1       0.98      0.98      0.98       126\n",
      "           2       0.88      0.90      0.89       116\n",
      "           3       0.84      0.83      0.84       107\n",
      "           4       0.86      0.90      0.88       110\n",
      "           5       0.86      0.85      0.86        87\n",
      "           6       0.91      0.93      0.92        87\n",
      "           7       0.88      0.85      0.87        99\n",
      "           8       0.93      0.78      0.85        89\n",
      "           9       0.81      0.88      0.85        94\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_class_report(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ldfdObCV5nR3"
   },
   "source": [
    "## Plotting the results\n",
    "\n",
    "Lets actually see if your model has trained correctly. Lets plot some of the images with their predicted labels. Since we don't have the predictions stored in our notebooks memory, we need to call the predict function here first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tx9YOlcO5nR4",
    "outputId": "4fdfd235-6c9c-45b3-be29-7448fa88eeee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "\n",
    "image_index = 15 ## Change me to see other predictions\n",
    "\n",
    "print(\"Predicted Label: \",preds[image_index])\n",
    "plt.imshow(X_test[image_index].reshape((28, 28)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCirI2V05nR-"
   },
   "source": [
    "Nice work! Since we didn't use all the data in the beginning, there is a chance our performance can improve. Go change the amount of data we use to see how it affects the accuracy of your model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "4_Image_Classification_model_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
